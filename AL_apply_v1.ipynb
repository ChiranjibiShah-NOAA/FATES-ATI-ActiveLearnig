{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["\n","**Applying Active Learning Models to Unseen Video Data (Google Cloud)**\n","---\n","\n"],"metadata":{"id":"3lQqi8yR1rhu"}},{"cell_type":"markdown","source":["**We need to connect the google drive with google colab to access the models and scripts. It may require google authentication to access your drive. We are utilizing T4 GPU runtime in google colab. Make sure to check and update your runtime.**"],"metadata":{"id":"EaV-k-L8VrzQ"}},{"cell_type":"code","source":["# Connect google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L4m3l_5DV0Hj","executionInfo":{"status":"ok","timestamp":1729870897477,"user_tz":300,"elapsed":21193,"user":{"displayName":"M M Nabi","userId":"17399996352713673631"}},"outputId":"014e661a-b08f-4c15-b1c2-0bcab4d5ff4b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["**Need to connect orginal directory to access code and models**"],"metadata":{"id":"vCZF2SNABKfC"}},{"cell_type":"code","source":["cd /content/drive/MyDrive/Google_colab/AL-MDN\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5rccOb2h2nBx","executionInfo":{"status":"ok","timestamp":1724687580788,"user_tz":300,"elapsed":310,"user":{"displayName":"M M Nabi","userId":"17399996352713673631"}},"outputId":"a00108bc-ecaa-4e73-8e54-7874b6780245"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Google_colab/AL-MDN\n"]}]},{"cell_type":"markdown","source":["*** This part is loading necessary packagees such as Google cloud storage, torch, common python packages. We are also importing some funtion such as build_ssd_gmm, VOC_CLASSES from our Active learning model***"],"metadata":{"id":"Nb0WMkHcYJY0"}},{"cell_type":"code","source":["# load packages\n","from google.cloud import storage\n","import os\n","import cv2\n","import numpy as np\n","import sys\n","import torch\n","import torch.nn as nn\n","import argparse\n","import csv\n","\n","from ssd_gmm import build_ssd_gmm\n","from data import VOC_CLASSES\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"0zRoU98BWk8p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**This code list all the files from Google Cloud Storage. The videos are stored in the cloud storage for processing**"],"metadata":{"id":"e5H5A8uBaxsH"}},{"cell_type":"code","source":["# Function to list files from GCS\n","def list_files_from_bucket(bucket_name, prefix):\n","    client = storage.Client.create_anonymous_client()\n","    files = [blob.name for blob in client.list_blobs(bucket_name, prefix=prefix)]\n","    return files"],"metadata":{"id":"t-HnaAn5CmTk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**This code block takes different input**\n","1. Trained Model\n","2. Google Cloud Bucket name & directory\n","3. Frame Rate to extract video frames\n","\n"],"metadata":{"id":"atlrXnMKbWMz"}},{"cell_type":"code","source":["# Configuration\n","trained_model = 'weights/ssd300_AL_VOC_id_1_num_labels_110000_120000.pth'\n","bucket = 'nmfs_odp_sefsc'\n","prefix = 'PEMD/VIDEO_DATA/GOM_REEF_FISH/SoJo_2022'\n","frame_rate = 5"],"metadata":{"id":"wbEpJ6z3W_Ni"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**This code block loads the trained models. The function build_ssd_gmm initialize our model.**"],"metadata":{"id":"Mj7VZh9sdmCM"}},{"cell_type":"code","source":["if torch.cuda.is_available():\n","    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n","\n","# Initialize SSD\n","net = build_ssd_gmm('test', 300, 145)\n","net = nn.DataParallel(net)\n","net.load_state_dict(torch.load(trained_model, map_location=torch.device('cpu')))\n","net.eval()"],"metadata":{"id":"1Q3pIuGlXDsW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724687740867,"user_tz":300,"elapsed":16318,"user":{"displayName":"M M Nabi","userId":"17399996352713673631"}},"outputId":"86071478-0507-4f96-d482-aa9b0b137e0b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataParallel(\n","  (module): SSD_GMM(\n","    (vgg): ModuleList(\n","      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (6): ReLU(inplace=True)\n","      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (8): ReLU(inplace=True)\n","      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (11): ReLU(inplace=True)\n","      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (13): ReLU(inplace=True)\n","      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (15): ReLU(inplace=True)\n","      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n","      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (18): ReLU(inplace=True)\n","      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (20): ReLU(inplace=True)\n","      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (22): ReLU(inplace=True)\n","      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (25): ReLU(inplace=True)\n","      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (27): ReLU(inplace=True)\n","      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (29): ReLU(inplace=True)\n","      (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n","      (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n","      (32): ReLU(inplace=True)\n","      (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n","      (34): ReLU(inplace=True)\n","    )\n","    (L2Norm): L2Norm()\n","    (extras): ModuleList(\n","      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","      (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n","      (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","      (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n","    )\n","    (loc_mu_1): ModuleList(\n","      (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (loc_var_1): ModuleList(\n","      (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (loc_pi_1): ModuleList(\n","      (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (loc_mu_2): ModuleList(\n","      (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (loc_var_2): ModuleList(\n","      (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (loc_pi_2): ModuleList(\n","      (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (loc_mu_3): ModuleList(\n","      (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (loc_var_3): ModuleList(\n","      (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (loc_pi_3): ModuleList(\n","      (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (loc_mu_4): ModuleList(\n","      (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (loc_var_4): ModuleList(\n","      (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (loc_pi_4): ModuleList(\n","      (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (conf_mu_1): ModuleList(\n","      (0): Conv2d(512, 580, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 580, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (conf_var_1): ModuleList(\n","      (0): Conv2d(512, 580, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 580, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (conf_pi_1): ModuleList(\n","      (0): Conv2d(512, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (conf_mu_2): ModuleList(\n","      (0): Conv2d(512, 580, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 580, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (conf_var_2): ModuleList(\n","      (0): Conv2d(512, 580, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 580, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (conf_pi_2): ModuleList(\n","      (0): Conv2d(512, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (conf_mu_3): ModuleList(\n","      (0): Conv2d(512, 580, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 580, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (conf_var_3): ModuleList(\n","      (0): Conv2d(512, 580, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 580, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (conf_pi_3): ModuleList(\n","      (0): Conv2d(512, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (conf_mu_4): ModuleList(\n","      (0): Conv2d(512, 580, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 580, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (conf_var_4): ModuleList(\n","      (0): Conv2d(512, 580, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 870, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 580, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (conf_pi_4): ModuleList(\n","      (0): Conv2d(512, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): Conv2d(1024, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (2): Conv2d(512, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (3): Conv2d(256, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4-5): 2 x Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (softmax): Softmax(dim=-1)\n","  )\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["**This funtion extracts frames at a defined frame rate. It saves the frames as .JPG format and stores that frames in a temporary drectory**"],"metadata":{"id":"xdrXLuFphZjV"}},{"cell_type":"code","source":["def extract_frames(video_file, output_dir, desired_fps):\n","    cap = cv2.VideoCapture(video_file)\n","    if not cap.isOpened():\n","        print(f\"Error opening video file {video_file}\")\n","        return []\n","\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    frame_count = -1\n","    extracted_frames = []\n","\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        frame_count += 1\n","        if frame_count % int(fps / desired_fps) == 0:\n","            frame_identifier = frame_count // int(fps / desired_fps)\n","            filename = f\"{os.path.splitext(os.path.basename(video_file))[0]}_{frame_identifier}.jpg\"\n","            output_path = os.path.join(output_dir, filename)\n","            cv2.imwrite(output_path, frame)\n","            extracted_frames.append((output_path, frame_identifier))\n","            print(f\"Frame {frame_identifier} saved as {filename}\")\n","\n","    cap.release()\n","    return extracted_frames"],"metadata":{"id":"aYHaXWOhXJCW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**This code block define the directory for temporary directory to store extracted frames. In addition, it also shows the ourput directory to save the output as VIAME csv format. If the folder doesn't exisit, it will create necessary direcotries.**"],"metadata":{"id":"rPS9BmJVju7Z"}},{"cell_type":"code","source":["# Define directories\n","temp_dir = 'temp_image'\n","output_dir = 'output'\n","\n","os.makedirs(temp_dir, exist_ok=True)\n","os.makedirs(output_dir, exist_ok=True)"],"metadata":{"id":"4B72jKs0XdGR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Function to process a single video\n","def process_video(video_path):\n","    extracted_frames = extract_frames(video_path, temp_dir, frame_rate)\n","    if not extracted_frames:\n","        return\n","\n","    video_name = os.path.splitext(os.path.basename(video_path))[0]\n","    csv_file_path = os.path.join(output_dir, f'detection_{video_name}.csv')\n","\n","    csv_header = ['# 1: Detection or Track-id', '2: Video or Image Identifier', '3: Unique Frame Identifier',\n","                  '4-7: Img-bbox(TL_x', 'TL_y', 'BR_x', 'BR_y)', '8: Detection or Length Confidence',\n","                  '9: Target Length (0 or -1 if invalid)', '10-11+: Repeated Species', 'Confidence Pairs or Attributes']\n","\n","    csv_data = [csv_header]\n","\n","    for frame_path, frame_id in extracted_frames:\n","        image = cv2.imread(frame_path)\n","\n","        x = cv2.resize(image, (300, 300)).astype(np.float32)\n","        x -= (104.0, 117.0, 123.0)\n","        x = x.astype(np.float32)\n","        x = x[:, :, ::-1].copy()\n","        x = torch.from_numpy(x).permute(2, 0, 1).to(device)\n","        xx = x.unsqueeze(0)\n","\n","        with torch.no_grad():\n","            detections = net(xx)\n","\n","        detections_to_save = []\n","\n","        for i in range(detections.size(1)):\n","            j = 0\n","            while detections[0, i, j, 0] >= 0.5:\n","                score = detections[0, i, j, 0].item()\n","                label_name = VOC_CLASSES[i - 1]\n","                pt = (detections[0, i, j, 1:5] * torch.Tensor([image.shape[1], image.shape[0], image.shape[1], image.shape[0]])).cpu().numpy()\n","                bbox = [int(pt[0]), int(pt[1]), int(pt[2]), int(pt[3])]\n","                confidence = f\"{score:.2f}\"\n","                class_name = label_name\n","                detections_to_save.append([j + 1, os.path.basename(frame_path), frame_id, *bbox, confidence, -1, class_name, confidence])\n","                j += 1\n","\n","        csv_data.extend(detections_to_save)\n","\n","    with open(csv_file_path, 'w', newline='') as csvfile:\n","        csv_writer = csv.writer(csvfile)\n","        csv_writer.writerows(csv_data)\n","\n","    print(f'Detections saved to {csv_file_path}')\n","\n","    for frame_path, _ in extracted_frames:\n","        os.remove(frame_path)"],"metadata":{"id":"oJv5VR6BDp-1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Process videos from GCS\n","files = list_files_from_bucket(bucket, prefix)\n","for file_name in files:\n","    video_url = os.path.join('https://storage.googleapis.com', bucket, file_name)\n","    print(f\"Processing video: {video_url}\")\n","    process_video(video_url)"],"metadata":{"id":"6Q6vUY6CXnIu","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1724687773401,"user_tz":300,"elapsed":4182,"user":{"displayName":"M M Nabi","userId":"17399996352713673631"}},"outputId":"9d83cc46-8971-4823-bef6-4ad83c62a2e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing video: https://storage.googleapis.com/nmfs_odp_sefsc/PEMD/VIDEO_DATA/GOM_REEF_FISH/SoJo_2022/942205001_cam3.avi\n","Frame 0 saved as 942205001_cam3_0.jpg\n","Frame 1 saved as 942205001_cam3_1.jpg\n","Frame 2 saved as 942205001_cam3_2.jpg\n","Frame 3 saved as 942205001_cam3_3.jpg\n","Frame 4 saved as 942205001_cam3_4.jpg\n","Frame 5 saved as 942205001_cam3_5.jpg\n","Frame 6 saved as 942205001_cam3_6.jpg\n","Frame 7 saved as 942205001_cam3_7.jpg\n","Frame 8 saved as 942205001_cam3_8.jpg\n","Frame 9 saved as 942205001_cam3_9.jpg\n","Frame 10 saved as 942205001_cam3_10.jpg\n","Frame 11 saved as 942205001_cam3_11.jpg\n","Frame 12 saved as 942205001_cam3_12.jpg\n","Frame 13 saved as 942205001_cam3_13.jpg\n","Frame 14 saved as 942205001_cam3_14.jpg\n","Frame 15 saved as 942205001_cam3_15.jpg\n","Frame 16 saved as 942205001_cam3_16.jpg\n","Frame 17 saved as 942205001_cam3_17.jpg\n","Frame 18 saved as 942205001_cam3_18.jpg\n","Frame 19 saved as 942205001_cam3_19.jpg\n","Frame 20 saved as 942205001_cam3_20.jpg\n","Frame 21 saved as 942205001_cam3_21.jpg\n","Frame 22 saved as 942205001_cam3_22.jpg\n","Frame 23 saved as 942205001_cam3_23.jpg\n","Frame 24 saved as 942205001_cam3_24.jpg\n","Frame 25 saved as 942205001_cam3_25.jpg\n","Frame 26 saved as 942205001_cam3_26.jpg\n","Frame 27 saved as 942205001_cam3_27.jpg\n","Frame 28 saved as 942205001_cam3_28.jpg\n","Frame 29 saved as 942205001_cam3_29.jpg\n","Frame 30 saved as 942205001_cam3_30.jpg\n","Frame 31 saved as 942205001_cam3_31.jpg\n","Frame 32 saved as 942205001_cam3_32.jpg\n","Frame 33 saved as 942205001_cam3_33.jpg\n","Frame 34 saved as 942205001_cam3_34.jpg\n","Frame 35 saved as 942205001_cam3_35.jpg\n","Frame 36 saved as 942205001_cam3_36.jpg\n","Frame 37 saved as 942205001_cam3_37.jpg\n","Frame 38 saved as 942205001_cam3_38.jpg\n","Frame 39 saved as 942205001_cam3_39.jpg\n","Frame 40 saved as 942205001_cam3_40.jpg\n","Frame 41 saved as 942205001_cam3_41.jpg\n","Frame 42 saved as 942205001_cam3_42.jpg\n","Frame 43 saved as 942205001_cam3_43.jpg\n","Frame 44 saved as 942205001_cam3_44.jpg\n","Frame 45 saved as 942205001_cam3_45.jpg\n","Frame 46 saved as 942205001_cam3_46.jpg\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-f5bbdac3055d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvideo_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://storage.googleapis.com'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing video: {video_url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprocess_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-808f317a0a58>\u001b[0m in \u001b[0;36mprocess_video\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Function to process a single video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mextracted_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextracted_frames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-c4f9918b2521>\u001b[0m in \u001b[0;36mextract_frames\u001b[0;34m(video_file, output_dir, desired_fps)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{os.path.splitext(os.path.basename(video_file))[0]}_{frame_identifier}.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mextracted_frames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_identifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Frame {frame_identifier} saved as {filename}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["**This shell command is OPTIONAL. If you already complete running your model, the bottom command is not required. Required if you want to run all the code at a time.**"],"metadata":{"id":"4MYWOWxGXsOe"}},{"cell_type":"code","source":["!python eval_voc_viame_videos_2.py --trained_model weights/ssd300_AL_VOC_id_1_num_labels_110000_120000.pth --bucket nmfs_odp_sefsc --prefix PEMD/VIDEO_DATA/GOM_REEF_FISH/SoJo_2022 --frame_rate 5\n"],"metadata":{"id":"kS-rka41WD1c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","**References**\n","\n","```\n","This work is adapted from AL-MDN, and SSD.\n","\n","If you find this work useful, please feel free to cite:\n","\n","@inproceedings{nabi2023probabilistic,\n","  title={Probabilistic Model-Based Active Learning with Attention Mechanism for Fish Species Recognition},\n","  author={Nabi, MM and Shah, Chiranjibi and Alaba, Simegnew Yihunie and Prior, Jack and Campbell, Matthew D and Wallace, Farron and Moorhead, Robert and Ball, John E},\n","  booktitle={OCEANS 2023-MTS/IEEE US Gulf Coast},\n","  pages={1--8},\n","  year={2023},\n","  organization={IEEE}\n","}\n","```\n","\n"],"metadata":{"id":"XK_CHfLiZ7rs"}}]}